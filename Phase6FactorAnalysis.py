import os
import pandas as pd
from sklearn.decomposition import FactorAnalysis

# 1ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
merged_file = r'E:\MY.PROJECT.1\VS\.py\bigData\temp_silver\merged_dataset.parquet'
df = pd.read_parquet(merged_file)

# 2ï¸âƒ£ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„
features = [
    'temperature_c',   # Ù…Ù† Weather
    'humidity',
    'rain_mm',
    'wind_speed_kmh',
    'visibility_m_x',
    'air_pressure_hpa',
    'vehicle_count',   # Ù…Ù† Traffic
    'avg_speed_kmh',
    'accident_count'
]

# ØªØ£ÙƒØ¯ Ø¥Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…ÙˆØ¬ÙˆØ¯Ø©
df_features = df[features].dropna()

# 3ï¸âƒ£ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„
n_factors = 3  # Ù†Ø±ÙŠØ¯ 1-3 Ø¹ÙˆØ§Ù…Ù„ Ù…Ø®ÙÙŠØ©
fa = FactorAnalysis(n_components=n_factors, random_state=42)
fa.fit(df_features)

# 4ï¸âƒ£ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Factor Loadings (Ø§Ù„Ø£ÙˆØ²Ø§Ù†)
loadings = pd.DataFrame(fa.components_.T, index=features, columns=[f'Factor_{i+1}' for i in range(n_factors)])

# 5ï¸âƒ£ Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Gold layer
gold_dir = r'E:\MY.PROJECT.1\VS\.py\bigData\gold_layer'
os.makedirs(gold_dir, exist_ok=True)
factor_loadings_file = os.path.join(gold_dir, 'factor_loadings.csv')
loadings.to_csv(factor_loadings_file)
print(f"âœ… Factor loadings saved to: {factor_loadings_file}")

# 6ï¸âƒ£ Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø±ÙŠØ± ØªÙØ³ÙŠØ± Ø£ÙˆÙ„ÙŠ
print("\nğŸ“Š Factor Loadings Table:")
print(loadings)

# ØªÙ„Ù…ÙŠØ­ Ù„Ù„ØªÙØ³ÙŠØ±:
print("\nğŸ”¹ Interpretation Hint:")
for i in range(n_factors):
    factor = loadings.iloc[:, i]
    top_vars = factor.abs().sort_values(ascending=False).head(3).index.tolist()
    print(f"Factor_{i+1} likely influenced by: {', '.join(top_vars)}")
